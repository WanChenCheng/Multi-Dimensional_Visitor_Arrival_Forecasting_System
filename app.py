import streamlit as st

# Important: st.set_page_config must come before other Streamlit commands
st.set_page_config(
    page_title="åœ‹æ³°äººå£½ - ç”¨æˆ¶è¡Œç‚ºé æ¸¬å·¥å…·", 
    layout="wide", 
    initial_sidebar_state="collapsed"
)


import pandas as pd
import numpy as np
import base64
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go

# Function to load image as Base64
@st.cache_data
def get_base64_image(path: str) -> str:
    with open(path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()

# Load and embed logo
img_base64 = get_base64_image("logo.png")

# Custom CSS
theme_css = """
<style>
  body { background-color: #e9f7f5; }
  .stApp { background-color: #e9f7f5; color: #333333; }

  /* Hide default Streamlit header/menu */
  header, footer { visibility: hidden; height: 0; margin: 0; padding: 0; }

  /* Multiselect tag pills */
  div[data-baseweb="tag"] {
      background-color: #4fc08d !important;
  }
  div[data-baseweb="tag"] > span:first-child,
  div[data-baseweb="tag"] svg {
      color: #ffffff !important;
  }

  /* Dropdown selected options */
  div[data-baseweb="option"][aria-selected="true"] {
      background-color: #4fc08d !important;
      color: #ffffff !important;
  }

  /* File uploader hover */
  input[type="file"]::file-selector-button:hover {
      background-color: #ffffff !important;
      color: #4fc08d !important;
      border: 1px solid #4fc08d !important;
  }

  /* Button hover & active */
  div[data-testid="stButton"] > button:hover {
      background-color: #ffffff !important;
      color: #4fc08d !important;
      border: 1px solid #4fc08d !important;
  }
  div[data-testid="stButton"] > button:active {
      background-color: #4fc08d !important;
      color: #ffffff !important;
  }

  /* Form and expander */
  div[data-testid="stForm"],
  div[data-testid="stExpander"] > div:first-child {
      background-color: #f8fffc !important;
      border-radius: 12px;
      border: 1px solid #cceee4;
      padding: 16px;
  }
  div[data-testid="stExpander"] > summary {
      font-size: 1.15rem !important;
      font-weight: 600;
      color: #2a6154;
  }
</style>
"""
st.markdown(theme_css, unsafe_allow_html=True)

# Single consolidated header with larger logo
st.markdown(
    f"""
    <div style="display:flex;align-items:center;margin-bottom:20px;">
        <img src="data:image/png;base64,{img_base64}" alt="logo" style="width:80px;height:auto;margin-right:12px;" />
        <h1 style="margin:0;color:#1f3f3e;font-size:2.5rem;">åœ‹æ³°äººå£½ - å¤šå…ƒè¨ªå®¢é€²ç«™è¡Œç‚ºé æ¸¬å·¥å…·</h1>
    </div>
    """,
    unsafe_allow_html=True
)

# å˜—è©¦è¼‰å…¥ TensorFlow å’Œç›¸é—œå¥—ä»¶
try:
    from tensorflow.keras.models import load_model
    from tensorflow.keras.preprocessing.sequence import pad_sequences
    from joblib import load
    import joblib
    TF_AVAILABLE = True
except ImportError as e:
    st.error(f"è¼‰å…¥ä¾è³´å¥—ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    TF_AVAILABLE = False

# åˆå§‹åŒ– session state
if "prediction_data" not in st.session_state:
    st.session_state.prediction_data = None
if "all_columns" not in st.session_state:
    st.session_state.all_columns = []
if "uploaded_file_name" not in st.session_state:
    st.session_state.uploaded_file_name = None
if "processed_data" not in st.session_state:
    st.session_state.processed_data = None
if "raw_uploaded_data" not in st.session_state:
    st.session_state.raw_uploaded_data = None
if "start_date" not in st.session_state:
    st.session_state.start_date = None
if "end_date" not in st.session_state:
    st.session_state.end_date = None


# æ¨¡å‹èˆ‡ç·¨ç¢¼å™¨åƒæ•¸
SEQ_LEN = 10
cat_features = ['action_group', 'source', 'medium', 'platform']
num_features = ['staytime', 'has_shared', 'revisit_count']

# === æ¨¡å‹èˆ‡ç·¨ç¢¼å™¨è¼‰å…¥å°è£ ===
@st.cache_resource
def load_model_with_log():
    import os
    import joblib
    from tensorflow.keras.models import load_model

    log_lines = []
    log_lines.append("é–‹å§‹è¼‰å…¥æ¨¡å‹èˆ‡ç·¨ç¢¼å™¨...")

    # æ¨¡å‹
    model_file = "lstm_multi_output_model_v2.h5"
    model = load_model(model_file)
    model_size = os.path.getsize(model_file) / (1024 * 1024)
    log_lines.append(f"æ¨¡å‹æˆåŠŸè¼‰å…¥ï¼ˆ{model_size:.2f} MBï¼‰")

    # é¡åˆ¥ç·¨ç¢¼å™¨
    encoders = {}
    for col in cat_features:
        path = f"encoder_{col}.pkl"
        if not os.path.exists(path):
            raise FileNotFoundError(f"{path} ä¸å­˜åœ¨")
        encoder = joblib.load(path)
        encoders[col] = encoder
        log_lines.append(f"encoder_{col} è¼‰å…¥æˆåŠŸï¼ˆé¡åˆ¥æ•¸: {len(encoder.classes_)}ï¼‰")

    # æ•¸å€¼ scaler
    scalers = {}
    for col in num_features:
        path = f"scaler_feature_{col}.pkl"
        if not os.path.exists(path):
            raise FileNotFoundError(f"{path} ä¸å­˜åœ¨")
        scaler = joblib.load(path)
        scalers[col] = scaler
        log_lines.append(f"scaler_{col} è¼‰å…¥æˆåŠŸ")

    log_lines.append("æ‰€æœ‰æ¨¡å‹èˆ‡ç·¨ç¢¼å™¨çš†æˆåŠŸè¼‰å…¥")
    return model, encoders, scalers, log_lines

# === è¼‰å…¥æ¨¡å‹èˆ‡åˆå§‹åŒ– ===
if TF_AVAILABLE:
    with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹èˆ‡ç·¨ç¢¼å™¨..."):
        model, encoders, scalers, load_log = load_model_with_log()

    st.success("æ¨¡å‹èˆ‡ç‰¹å¾µç·¨ç¢¼å™¨å·²æˆåŠŸè¼‰å…¥")

    with st.expander("æŸ¥çœ‹è©³ç´°è¼‰å…¥è¨˜éŒ„", expanded=False):
        for line in load_log:
            st.markdown(f"- {line}")
else:
    st.error("ç„¡æ³•è¼‰å…¥æ¨¡å‹ï¼Œè«‹ç¢ºèª TensorFlow å®‰è£ç‹€æ…‹")


# 1. å®šç¾©ç­‰ç´šæ˜ å°„å‡½å¼
def get_level(action_group: str) -> float:
    # æª¢æŸ¥è¼¸å…¥æ˜¯å¦ç‚ºæœ‰æ•ˆå€¼
    if action_group is None or pd.isna(action_group) or action_group == '':
        return -1
        
    # è½‰æ›ç‚ºå­—ç¬¦ä¸²ä»¥ç¢ºä¿ä¸€è‡´æ€§
    action_group = str(action_group).strip()
    
    # ç­‰ç´š 0
    if action_group in {"å…¶ä»–", "ä¿éšªè¦–åœ–ã€ä¿å–®æ˜ç´°ã€è³‡ç”¢ç¸½è¦½ã€ä¿éšªæ˜ç´°"}:
        return 0
    # ç­‰ç´š 1
    if action_group == "æ‰¾æœå‹™ï¼ˆå°‹æ±‚æœå‹™èˆ‡å®¢æœï¼‰":
        return 1
    # ç­‰ç´š 2
    if "å•†å“è³‡è¨Šé " in action_group or action_group == "å¥½åº·å„ªæƒ ":
        return 2
    # ç­‰ç´š 3
    combo3 = {
        "è‡ªç”±é…ï¼æŠ•è³‡è¦åŠƒ", "è‡ªç”±é…", "è¨‚è£½ä¿éšªçµ„åˆ", "è‡ªç”±é…ï¼å¥—é¤", "è‡ªç”±é…ï¼ä¿éšœè¦åŠƒ"
    }
    if action_group in combo3 or action_group.startswith("è©¦ç®—"):
        return 3
    # ç­‰ç´š 4
    result4 = {
        "è‡ªç”±é…ï¼ä¿éšœè¦åŠƒè©¦ç®—çµæœ",
        "è¨‚è£½ä¿éšªçµ„åˆï¼äººèº«è¦åŠƒè©¦ç®—çµæœ",
        "æˆ‘çš„ä¿éšªè©¦ç®—çµæœ",
        "è¨‚è£½ä¿éšªçµ„åˆï¼æŠ•è³‡è¦åŠƒè©¦ç®—çµæœ",
        "è‡ªç”±é…ï¼é…ç½®æˆ‘çš„åŸºé‡‘è©¦ç®—çµæœ"
    }
    if action_group in result4:
        return 4
    # ç­‰ç´š 5
    if action_group in {
        "ä¿å­˜èˆ‡åˆ†äº«è©¦ç®—çµæœ",
        "ä¿å­˜èˆ‡åˆ†äº«è‡ªç”±é…ã€è¨‚è£½çµ„åˆçµæœ",
        "Lineåˆ†äº«è½‰å‚³"
    }:
        return 5
    # ç­‰ç´š 6
    if action_group in {
        "æŒ‘é¸é ç´„é¡§å•",
        "é ç´„é¡§å•èˆ‡å•†å“è«®è©¢",
        "ç«‹å³æŠ•ä¿"
    }:
        return 6
    # ç­‰ç´š 7.x
    if action_group in {"æ–¹æ¡ˆç¢ºèª", "å¡«å¯«é ç´„è³‡æ–™"}:
        return 7.1
    if action_group in {"è³‡æ–™å¡«å¯«èˆ‡ç¢ºèª", "æŠ•ä¿è³‡æ ¼ç¢ºèª", "æ‰‹æ©Ÿé©—è­‰ç¢¼"}:
        return 7.2
    if action_group == "ç·šä¸Šç¹³è²»":
        return 7.3
    # ç­‰ç´š 8
    if action_group in {"å®Œæˆç¶²è·¯æŠ•ä¿", "å®ŒæˆO2O"}:
        return 8
    # æœªçŸ¥
    return -1

# 2. æ¨è–¦ç­–ç•¥å‡½å¼ï¼ˆä½¿ç”¨ next_action_group åƒæ•¸ï¼‰
def recommend_strategy(
        next_action_group: str,
        history: list[str],
        last_event_time: datetime
    ) -> str | None:

    # å„ªå…ˆæ¢ä»¶ï¼šè‹¥éå»10æ­¥å·²å®Œæˆè½‰æ›ï¼Œå‰‡æš«æ™‚ä¸æ¨è–¦è¡ŒéŠ·å»ºè­°
    if any("å®Œæˆç¶²è·¯æŠ•ä¿" in (ag or "") for ag in history[:10]):
        return "æ­¤ç”¨æˆ¶æ–¼æœŸé–“å…§å·²å®Œæˆç¶²è·¯æŠ•ä¿"
    if any("å®ŒæˆO2O" in (ag or "") for ag in history[:10]):
        return "æ­¤ç”¨æˆ¶æ–¼æœŸé–“å…§å·²å®Œæˆé ç´„O2O"
    
    # æª¢æŸ¥ next_action_group æ˜¯å¦ç‚º None æˆ–ç©ºå€¼
    if next_action_group is None or pd.isna(next_action_group) or next_action_group == '':
        return None
        
    # è™•ç†æ™‚å€å•é¡Œï¼šçµ±ä¸€è½‰æ›ç‚º naive datetime
    now = datetime.now()
    if hasattr(last_event_time, 'tz_localize'):
        # å¦‚æœæ˜¯ pandas Timestamp ä¸”æœ‰æ™‚å€ä¿¡æ¯ï¼Œè½‰æ›ç‚º naive
        if last_event_time.tz is not None:
            last_event_time = last_event_time.tz_localize(None)
    elif hasattr(last_event_time, 'tzinfo'):
        # å¦‚æœæ˜¯ datetime ä¸”æœ‰æ™‚å€ä¿¡æ¯ï¼Œè½‰æ›ç‚º naive
        if last_event_time.tzinfo is not None:
            last_event_time = last_event_time.replace(tzinfo=None)

    # ç­‰ç´š 0
    if next_action_group in {"å…¶ä»–", "ä¿éšªè¦–åœ–ã€ä¿å–®æ˜ç´°ã€è³‡ç”¢ç¸½è¦½ã€ä¿éšªæ˜ç´°"}:
        return "æš«ç„¡å»ºè­°ï¼ŒæŒçºŒè§€å¯Ÿ"

    # ç­‰ç´š 1ï¼šæ‰¾æœå‹™
    if next_action_group == "æ‰¾æœå‹™ï¼ˆå°‹æ±‚æœå‹™èˆ‡å®¢æœï¼‰":
        count = history[:10].count("æ‰¾æœå‹™ï¼ˆå°‹æ±‚æœå‹™èˆ‡å®¢æœï¼‰")
        if count == 0:
            return "ç•«é¢ä¸Šæ–¹ç®­é ­æç¤ºå®¢æœé¸å–®ä½ç½®"
        elif count > 3:
            return "è®“å³ä¸‹è§’çš„é˜¿ç™¼çš„ã€ŒHi éœ€è¦å¹«å¿™å—ã€unhide"
        else:
            return None

    # ç­‰ç´š 2ï¼šå•†å“è³‡è¨Šé 
    if "å•†å“è³‡è¨Šé " in next_action_group:
        last_action = history[0]  # æœ€å¾Œä¸€æ­¥ï¼ˆlast_action_groupï¼‰
        # å¦‚æœæœ€å¾Œä¸€æ­¥ä¸åŒ…å«ç‰¹å®šé—œéµå­—ï¼Œæ‰è€ƒæ…®æ¨å‹•è©¦ç®—
        if all(kw not in (last_action or "") for kw in ["æ‰¾æœå‹™", "è©¦ç®—", "è‡ªç”±é…", "è¨‚è£½ä¿éšªçµ„åˆ"]):
            cnt = sum(1 for ag in history[:10] if ag and "å•†å“è³‡è¨Šé " in ag)
            if cnt >= 3:
                return "é¡¯ç¤ºè©¦ç®—å…¥å£ï¼Œæ¨å‹•è©¦ç®—"
    
        return None

    # ç­‰ç´š 2ï¼šå¥½åº·å„ªæƒ 
    if next_action_group == "å¥½åº·å„ªæƒ ":
        last_action = history[0]  # æœ€å¾Œä¸€å€‹ action_group
        if last_action != "å¥½åº·å„ªæƒ ":
            return "å½ˆçª—é¡¯ç¤ºå¥½åº·å„ªæƒ ç›¸é—œè³‡è¨Š"

    # ç­‰ç´š 3ï¼šæŒ‘é¸çµ„åˆ
    combo3 = {"è‡ªç”±é…ï¼æŠ•è³‡è¦åŠƒ", "è‡ªç”±é…", "è¨‚è£½ä¿éšªçµ„åˆ", "è‡ªç”±é…ï¼å¥—é¤", "è‡ªç”±é…ï¼ä¿éšœè¦åŠƒ"}
    if next_action_group in combo3:
        # å–å‡ºæœ€è¿‘ä¸‰å€‹è¡Œç‚º
        recent_actions = history[:3]
        # å¦‚æœéƒ½æ²’æœ‰åŒ…å«ã€Œè‡ªç”±é…ã€æˆ–ã€Œè¨‚è£½ä¿éšªçµ„åˆã€ï¼Œæ‰é¡¯ç¤ºå½ˆçª—
        if all(
            not any(kw in (ag or "") for kw in ["è‡ªç”±é…", "è¨‚è£½ä¿éšªçµ„åˆ"])
            for ag in recent_actions
        ):
            prompt = (
                "ä¸çŸ¥é“å¦‚ä½•é–‹å§‹å—ï¼Ÿç°¡å–®ä¸‰å€‹å•é¡Œï¼Œè®“ç³»çµ±æä¾›æœ€é©åˆä½ çš„å•†å“ï¼"
                if next_action_group == "è¨‚è£½ä¿éšªçµ„åˆ"
                else "ä¸€éµæ­é…å€‹äººåŒ–çš„å•†å“çµ„åˆï¼Œåªè¦ 2 åˆ†é˜ï¼"
            )
            return f"å½ˆçª—ï¼šã€Œ{prompt}ã€"
            
    # ç­‰ç´š 3ï¼šè©¦ç®—
    if next_action_group.startswith("è©¦ç®—"):
        last_ag = history[0] or ""
        if not any(keyword in last_ag for keyword in ["æ‰¾æœå‹™", "è©¦ç®—", "è‡ªç”±é…", "è¨‚è£½ä¿éšªçµ„åˆ"]):
            return "å½ˆçª—ï¼šã€Œä¸€éµå¸¶ä½ å®Œæˆè©¦ç®—ï¼Œåªè¦ 2 æ­¥é©Ÿï¼Œå–å¾—å•†å“è²»ç”¨ä¼°ç®—ã€"

    # ç­‰ç´š 4ï¼šè©¦ç®—çµæœ
    result4 = {
        "è‡ªç”±é…ï¼ä¿éšœè¦åŠƒè©¦ç®—çµæœ",
        "è¨‚è£½ä¿éšªçµ„åˆï¼äººèº«è¦åŠƒè©¦ç®—çµæœ",
        "æˆ‘çš„ä¿éšªè©¦ç®—çµæœ",
        "è¨‚è£½ä¿éšªçµ„åˆï¼æŠ•è³‡è¦åŠƒè©¦ç®—çµæœ",
        "è‡ªç”±é…ï¼é…ç½®æˆ‘çš„åŸºé‡‘è©¦ç®—çµæœ"
    }
    if next_action_group in result4:
        last_ag = history[0] or ""
        if any(keyword in last_ag for keyword in ["è©¦ç®—", "è‡ªç”±é…", "è¨‚è£½ä¿éšªçµ„åˆ"]):
            return "æä¾›é€²åº¦æé†’ï¼šå°±å¿«å®Œæˆäº†ï¼è©¦ç®—çµæœå³å°‡ç”¢ç”Ÿ"

    # ç­‰ç´š 5ï¼šä¿å­˜ï¼åˆ†äº«çµæœ
    if next_action_group in {
        "ä¿å­˜èˆ‡åˆ†äº«è©¦ç®—çµæœ",
        "ä¿å­˜èˆ‡åˆ†äº«è‡ªç”±é…ã€è¨‚è£½çµ„åˆçµæœ"
    }:
        if any("çµæœ" in (ag or "") for ag in history[:3]):
            return "è«®è©¢æŒ‰éˆ•æç¤ºï¼šã€Œå°è©¦ç®—çµæœæœ‰ç–‘å•å—ï¼Ÿé ç´„å…è²»å°ˆäººè§£è®€ï¼ã€"
    
    if next_action_group == "Lineåˆ†äº«è½‰å‚³":
        if any("çµæœ" in (ag or "") for ag in history[:3]):
            return "å½ˆçª—é¼“å‹µæ¨è–¦ã€æ¨æ’­æ¨è–¦çå‹µæ©Ÿåˆ¶æˆ–åˆ†äº«å›é¥‹æ´»å‹•"

    # ç­‰ç´š 6ï¼šæŒ‘é¡§å• / è«®è©¢éœ€æ±‚
    if next_action_group in {"æŒ‘é¸é ç´„é¡§å•", "é ç´„é¡§å•èˆ‡å•†å“è«®è©¢"}:
        return "å½ˆçª—æ¨è–¦é¡§å•ï¼šã€Œé€™ä½å°ˆå®¶æœ€æ“…é•·XXéšªï¼Œ3 åˆ†é˜å…§ç¢ºèªé ç´„ã€"
    if next_action_group == "ç«‹å³æŠ•ä¿":
        return "ç«‹å³æŠ•ä¿æŒ‰éˆ•æˆ–æ©«å¹…CTAï¼šã€Œç«‹å³æŠ•ä¿äº«å„ªæƒ ï¼ã€"

    # ç­‰ç´š 7.1ï¼šæ–¹æ¡ˆç¢ºèª / å¡«å¯«é ç´„è³‡æ–™
    if next_action_group in {"æ–¹æ¡ˆç¢ºèª", "å¡«å¯«é ç´„è³‡æ–™"}:
        if now - last_event_time > timedelta(minutes=30):
            return "ç™¼EDMæé†’å®ŒæˆæŠ•ä¿æˆ–é ç´„ï¼šã€Œä¸Šæ¬¡é‚„æ²’å¡«å®Œï¼Ÿé»æ­¤ä¸€éµå›åˆ°æµç¨‹ã€"
        if now - last_event_time <= timedelta(minutes=5):
            return (
                "é€²åº¦æé†’ï¼šã€Œå†ä¸‰æ­¥å³å¯å®ŒæˆæŠ•ä¿ã€"
                if next_action_group == "æ–¹æ¡ˆç¢ºèª"
                else "é€²åº¦æé†’ï¼šã€Œå†å…©æ­¥å³å¯å®Œæˆé ç´„ã€"
            )

    # ç­‰ç´š 7.2ï¼šè³‡æ–™å¡«å¯«èˆ‡ç¢ºèª / æŠ•ä¿è³‡æ ¼ç¢ºèª / æ‰‹æ©Ÿé©—è­‰ç¢¼
    if next_action_group in {"è³‡æ–™å¡«å¯«èˆ‡ç¢ºèª", "æŠ•ä¿è³‡æ ¼ç¢ºèª", "æ‰‹æ©Ÿé©—è­‰ç¢¼"}:
        if now - last_event_time > timedelta(minutes=30):
            return "ç™¼EDMæé†’å®ŒæˆæŠ•ä¿æˆ–é ç´„ï¼šã€Œä¸Šæ¬¡é‚„æ²’å¡«å®Œï¼Ÿé»æ­¤ä¸€éµå›åˆ°æµç¨‹ã€"
        if now - last_event_time <= timedelta(minutes=5):
            return (
                "é€²åº¦æé†’ï¼šã€Œé‚„å·®æœ€å¾Œä¸€æ­¥å°±OKï¼Œå³å°‡å®Œæˆé ç´„ã€"
                if next_action_group == "æ‰‹æ©Ÿé©—è­‰ç¢¼"
                else "é€²åº¦æé†’ï¼šã€Œé‚„å·®æœ€å¾Œå…©æ­¥å°±OKï¼Œå³å°‡å®ŒæˆæŠ•ä¿ã€"
            )

    # ç­‰ç´š 7.3ï¼šç·šä¸Šç¹³è²»
    if next_action_group == "ç·šä¸Šç¹³è²»":
        if now - last_event_time > timedelta(minutes=30):
            return "å¯„ç™¼EDMæé†’å®ŒæˆæŠ•ä¿æˆ–é ç´„ï¼šã€Œä¸Šæ¬¡é‚„æ²’å¡«å®Œï¼Ÿé»æ­¤ä¸€éµå›åˆ°æµç¨‹ã€"
        if now - last_event_time <= timedelta(minutes=5):
            return "é€²åº¦æé†’ï¼šã€Œé‚„å·®æœ€å¾Œä¸€æ­¥å°±OKï¼Œå³å°‡å®ŒæˆæŠ•ä¿ã€"

    # ç­‰ç´š 8ï¼šå®Œæˆç¶²æŠ• / å®ŒæˆO2O
    if next_action_group == "å®Œæˆç¶²è·¯æŠ•ä¿":
        if now - last_event_time > timedelta(minutes=30):
            return "å¯„ç™¼EDMæé†’å³å°‡å®ŒæˆæŠ•ä¿ï¼Œä¸¦é™„ä¸Šé€£çµã€Œé‚„å·®æœ€å¾Œä¸€æ­¥å°±OKï¼Œé»æˆ‘å›åˆ°æµç¨‹ã€"
    if now - last_event_time <= timedelta(minutes=5):
            return "é€²åº¦æé†’ï¼šã€Œé‚„å·®æœ€å¾Œä¸€æ­¥å°±OKï¼Œå³å°‡å®ŒæˆæŠ•ä¿ã€"
        
    if next_action_group == "å®ŒæˆO2O":
        if now - last_event_time > timedelta(minutes=30):
            return "å¯„ç™¼EDMæé†’å³å°‡å®Œæˆé ç´„ï¼Œä¸¦é™„ä¸Šé€£çµã€Œé‚„å·®æœ€å¾Œä¸€æ­¥å°±OKï¼Œé»æˆ‘å›åˆ°æµç¨‹ã€"
        if now - last_event_time <= timedelta(minutes=5):
            return "é€²åº¦æé†’ï¼šã€Œé‚„å·®æœ€å¾Œä¸€æ­¥å°±OKï¼Œå³å°‡å®ŒæˆæŠ•ä¿ã€"

    return None

# 3. æ ¹æ“š Top1~Top5 é¸å‡º next_action_group
def pick_next_action_group(row) -> str:
    candidates = []
    for i in range(1, 6):
        ag = row[f'Top{i}_next_action_group']
        conf = row[f'Top{i}_confidence']
        
        # æª¢æŸ¥ action_group æ˜¯å¦ç‚ºæœ‰æ•ˆå€¼
        if ag is None or pd.isna(ag) or ag == '':
            lvl = -1  # çµ¦ç„¡æ•ˆå€¼æœ€ä½ç­‰ç´š
        else:
            lvl = get_level(ag)
            
        candidates.append((ag, conf, lvl))
    
    # å…ˆæ¯”ç­‰ç´šï¼Œå†æ¯”æ©Ÿç‡ï¼Œéæ¿¾æ‰ç„¡æ•ˆå€¼
    valid_candidates = [(ag, conf, lvl) for ag, conf, lvl in candidates if lvl >= 0]
    
    if valid_candidates:
        best = max(valid_candidates, key=lambda x: (x[2], x[1]))
        return best[0]
    else:
        # å¦‚æœæ²’æœ‰æœ‰æ•ˆå€™é¸ï¼Œè¿”å›ç¬¬ä¸€å€‹éç©ºå€¼æˆ–é»˜èªå€¼
        for ag, conf, lvl in candidates:
            if ag is not None and not pd.isna(ag) and ag != '':
                return ag
        return "å…¶ä»–"  # é»˜èªå€¼

def safe_label_transform(encoder, value, default=0):
    """
    å®‰å…¨åœ°é€²è¡Œ label encodingï¼Œç¢ºä¿ä¸æœƒç”¢ç”Ÿè² å€¼
    """
    try:
        # è™•ç† NaN, None, ç©ºå­—ç¬¦ä¸²
        if pd.isna(value) or value is None or value == '' or value == 'nan':
            return default
        
        # è½‰æ›ç‚ºå­—ç¬¦ä¸²ï¼ˆä¿æŒèˆ‡è¨“ç·´æ™‚ä¸€è‡´ï¼‰
        str_value = str(value).strip()
        
        # å¦‚æœæ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œè¿”å›é»˜èªå€¼
        if str_value == '' or str_value == 'nan':
            return default
        
        # æª¢æŸ¥æ˜¯å¦åœ¨å·²çŸ¥é¡åˆ¥ä¸­
        if str_value in encoder.classes_:
            result = encoder.transform([str_value])[0]
            # ç¢ºä¿çµæœä¸æ˜¯è² æ•¸
            if result < 0:
                print(f"è­¦å‘Šï¼šç·¨ç¢¼çµæœç‚ºè² æ•¸ {result}ï¼Œä½¿ç”¨é»˜èªå€¼ {default}")
                return default
            return result
        else:
            # æœªçŸ¥é¡åˆ¥ï¼Œè¿”å›é»˜èªå€¼
            print(f"è­¦å‘Šï¼šæœªçŸ¥é¡åˆ¥ '{str_value}' (åŸå€¼: {value})ï¼Œä½¿ç”¨é»˜èªå€¼ {default}")
            return default
            
    except Exception as e:
        print(f"Label encoding éŒ¯èª¤ (å€¼: {value}): {e}ï¼Œä½¿ç”¨é»˜èªå€¼ {default}")
        return default

def safe_scale(scaler, value, default=0.0):
    """
    å®‰å…¨åœ°é€²è¡Œæ•¸å€¼æ¨™æº–åŒ–
    """
    try:
        # è™•ç† NaN, None
        if pd.isna(value) or value is None:
            return default
        
        # è½‰æ›ç‚ºæµ®é»æ•¸
        float_value = float(value)
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰é™æ•¸
        if not np.isfinite(float_value):
            return default
        
        # é€²è¡Œæ¨™æº–åŒ–
        scaled_value = scaler.transform([[float_value]])[0][0]
        
        # æª¢æŸ¥çµæœæ˜¯å¦æœ‰æ•ˆ
        if not np.isfinite(scaled_value):
            return default
        
        return scaled_value
        
    except Exception as e:
        print(f"Scaling éŒ¯èª¤ (å€¼: {value}): {e}ï¼Œä½¿ç”¨é»˜èªå€¼ {default}")
        return default

def validate_and_fix_sequence(seq, seq_name):
    """
    é©—è­‰ä¸¦ä¿®å¾©åºåˆ—ä¸­çš„ç„¡æ•ˆå€¼
    """
    seq = np.array(seq)
    
    # æª¢æŸ¥ä¸¦ä¿®å¾©è² å€¼
    negative_mask = seq < 0
    if np.any(negative_mask):
        print(f"è­¦å‘Šï¼š{seq_name} ä¸­ç™¼ç¾ {np.sum(negative_mask)} å€‹è² å€¼ï¼Œå·²ä¿®å¾©ç‚º 0")
        seq[negative_mask] = 0
    
    # æª¢æŸ¥ä¸¦ä¿®å¾© NaN å€¼
    nan_mask = ~np.isfinite(seq)
    if np.any(nan_mask):
        print(f"è­¦å‘Šï¼š{seq_name} ä¸­ç™¼ç¾ {np.sum(nan_mask)} å€‹ç„¡æ•ˆå€¼ï¼Œå·²ä¿®å¾©ç‚º 0")
        seq[nan_mask] = 0
    
    return seq

def predict_from_uploaded_csv(df):
    if model is None or encoders is None or scalers is None:
        st.error("æ¨¡å‹æœªæ­£ç¢ºè¼‰å…¥ï¼Œç„¡æ³•é€²è¡Œé æ¸¬")
        return pd.DataFrame()
    
    # æª¢æŸ¥å¿…è¦æ¬„ä½
    required_columns = ['user_pseudo_id', 'event_time', 'platform', 'action', 'action_group'] \
                       + cat_features + num_features
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        st.error(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_columns}")
        return pd.DataFrame()
    
    # è³‡æ–™é è™•ç†
    df = df.copy()
    df['event_time'] = pd.to_datetime(df['event_time'])
    
    # çµ±ä¸€è™•ç†æ™‚å€ï¼šå¦‚æœæœ‰æ™‚å€ä¿¡æ¯ï¼Œè½‰æ›ç‚º naive datetime
    if df['event_time'].dt.tz is not None:
        df['event_time'] = df['event_time'].dt.tz_localize(None)
    
    df = df.sort_values(by=["user_pseudo_id", "event_time"])
    
    results = []
    
    for user_id, group in df.groupby("user_pseudo_id"):
        try:
            # å–æœ€å¾Œ SEQ_LEN æ­¥
            last_steps = group.tail(SEQ_LEN)
            pad_len = SEQ_LEN - len(last_steps)
            
            # --- æ“·å– raw features ---
            last = last_steps.iloc[-1]
            raw_last_event_time   = last['event_time']
            raw_last_platform     = last['platform']
            raw_last_action       = last['action']
            raw_last_action_group = last['action_group']
            
            # å–å‰ 2~9 æ­¥çš„ raw action & action_group
            prev_records = {}
            for i in range(2, 11):
                if len(last_steps) >= i:
                    rec = last_steps.iloc[-i]
                    prev_records[f"-{i}_action"]        = rec['action']
                    prev_records[f"-{i}_action_group"]  = rec['action_group']
                else:
                    prev_records[f"-{i}_action"]        = None
                    prev_records[f"-{i}_action_group"]  = None
            
            # --- é¡åˆ¥ç‰¹å¾µç·¨ç¢¼ & å¡«å…… ---
            cat_inputs = []
            for col in cat_features:
                raw_vals = last_steps[col].tolist()
                encoded = [ safe_label_transform(encoders[col], v, default=0)
                            for v in raw_vals ]
                padded = [0]*pad_len + encoded
                seq = validate_and_fix_sequence(padded, f"{col}_sequence")
                cat_inputs.append(np.array(seq, dtype=np.int32).reshape(1, SEQ_LEN))
            
            # --- æ•¸å€¼ç‰¹å¾µæ¨™æº–åŒ– & å¡«å…… ---
            num_inputs = []
            for col in num_features:
                raw_vals = last_steps[col].tolist()
                scaled = [ safe_scale(scalers[col], v, default=0.0)
                           for v in raw_vals ]
                padded = [0.0]*pad_len + scaled
                seq = validate_and_fix_sequence(padded, f"{col}_sequence")
                num_inputs.append(np.array(seq, dtype=np.float32).reshape(1, SEQ_LEN))
            
            all_inputs = cat_inputs + num_inputs

            # é€²è¡Œé æ¸¬ä¸¦å– Top5
            y_pred_action_group, y_pred_online, y_pred_o2o = model.predict(all_inputs, verbose=0)
            top5_idx   = y_pred_action_group[0].argsort()[-5:][::-1]
            top5_confs = y_pred_action_group[0][top5_idx]
            inv_ag     = {i: v for i, v in enumerate(encoders['action_group'].classes_)}
            top5_actions = [inv_ag.get(idx, "æœªçŸ¥") for idx in top5_idx]
            
            # æ­£ç¢ºåœ° build ä¸­ä»‹ dictï¼Œæ³¨æ„ for è¿´åœˆå¾Œè¦æœ‰å†’è™Ÿ
            temp = {}
            for i in range(5):
                temp[f"Top{i+1}_next_action_group"] = top5_actions[i]
                temp[f"Top{i+1}_confidence"]       = round(float(top5_confs[i]), 4)
                
            # å†æŠŠé€™å€‹ dict å‚³çµ¦ pick_next_action_group
            next_ag = pick_next_action_group(temp)
            
            # è¨ˆç®—è¡ŒéŠ·ç­–ç•¥
            strategy = recommend_strategy(
                next_ag,
                [last['action_group']] + [ prev_records.get(f"-{i}_action_group") for i in range(1, 11) ],
                raw_last_event_time
            )
            
            # --- çµ„è£çµæœ ---
            result = {
                # ğŸ”‘ åŸºæœ¬èº«ä»½ä¿¡æ¯
                "user_pseudo_id": user_id,
                
                # ğŸ¯ å®Œæ•´Top5é æ¸¬ (æœ€é‡è¦ï¼Œæ”¾åœ¨å‰é¢)
                "Top1_next_action_group": top5_actions[0],
                "Top1_confidence": round(float(top5_confs[0]), 4),
                "Top2_next_action_group": top5_actions[1],
                "Top2_confidence": round(float(top5_confs[1]), 4),
                "Top3_next_action_group": top5_actions[2],
                "Top3_confidence": round(float(top5_confs[2]), 4),
                "Top4_next_action_group": top5_actions[3],
                "Top4_confidence": round(float(top5_confs[3]), 4),
                "Top5_next_action_group": top5_actions[4],
                "Top5_confidence": round(float(top5_confs[4]), 4),
                
                # ğŸ“Š è½‰æ›æ©Ÿç‡å’Œç­–ç•¥
                "Online_conversion_prob": round(float(y_pred_online[0][0]), 4),
                "O2O_reservation_prob": round(float(y_pred_o2o[0][0]), 4),
                "Marketing_Strategy": strategy,
                
                # ğŸ“± ç•¶å‰è¡Œç‚ºä¿¡æ¯
                "last_event_time": raw_last_event_time,
                "last_platform": raw_last_platform,
                "last_action": raw_last_action,
                "last_action_group": raw_last_action_group,
                
                # ğŸ“š æ­·å²è¡Œç‚ºè¨˜éŒ„
                **prev_records
            }
            
            results.append(result)
        
        except Exception as e:
            st.error(f"è™•ç†ç”¨æˆ¶ {user_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            continue
    
    return pd.DataFrame(results)

# UI ä»‹é¢
# streamlit run app.py

# =========================
# é é¢å®šç¾©èˆ‡åˆå§‹åŒ–
# =========================
pages = [
    "1. ä¸Šå‚³æª”æ¡ˆèˆ‡æ™‚é–“ç¯©é¸",
    "2. é æ¸¬èˆ‡çµæœ",
    "3. ç¯©é¸èˆ‡ä¸‹è¼‰æª”æ¡ˆ",
    "4. çµ±è¨ˆåœ–è¡¨åˆ†æ"
]

# åˆå§‹åŒ–é é¢ indexï¼ˆåªè·‘ä¸€æ¬¡ï¼‰
if "current_page_index" not in st.session_state:
    st.session_state.current_page_index = 0

# åˆå§‹åŒ–è³‡æ–™ç‹€æ…‹ï¼ˆåªè·‘ä¸€æ¬¡ï¼‰
if "raw_uploaded_data" not in st.session_state:
    st.session_state.raw_uploaded_data = None
if "filtered_input_data" not in st.session_state:
    st.session_state.filtered_input_data = None
if "prediction_data" not in st.session_state:
    st.session_state.prediction_data = None
if "all_columns" not in st.session_state:
    st.session_state.all_columns = []

# å–å¾—ç•¶å‰é é¢åç¨±èˆ‡ index
current_index = st.session_state.current_page_index
page = pages[current_index]

# =========================
# å´é‚Šæ¬„æ¨£å¼èˆ‡åŠŸèƒ½é¸å–®
# =========================
st.markdown("""<style>
    section[data-testid='stSidebar'] {
        background-color: #d8f3e8;
        padding: 1.5rem 1rem;
    }
    section[data-testid='stSidebar'] h2 {
        font-size: 20px;
        margin-bottom: 1rem;
        color: #2a6154;
    }
    section[data-testid='stSidebar'] div[role='radiogroup'] label {
        margin-bottom: 0.75rem;
        font-size: 16px;
        font-weight: normal;
        color: #333;
        padding-left: 0.2rem;
    }
    section[data-testid='stSidebar'] div[role='radiogroup'] input[type="radio"] {
        display: none;
    }
    section[data-testid='stSidebar'] div[role='radiogroup'] label[data-selected="true"] {
        font-size: 17px;
        font-weight: 700;
        color: #2a6154;
    }
</style>""", unsafe_allow_html=True)

with st.sidebar:
    st.markdown("## åŠŸèƒ½é¸å–®")
    selected = st.radio("åŠŸèƒ½é é¢", pages, index=current_index, label_visibility="collapsed")
    if selected != page:
        st.session_state.current_page_index = pages.index(selected)
        st.rerun()

# =========================
# å°è¦½æŒ‰éˆ•å‡½å¼ï¼ˆæ”¾åœ¨é é¢åº•éƒ¨å‘¼å«ï¼‰
# =========================
def render_next_page_button():
    col1, col2, col3, col4 = st.columns([1, 3, 3, 1])

    # ä¸Šä¸€é ï¼ˆåªæœ‰ç•¶ä¸æ˜¯ç¬¬ä¸€é æ™‚æ‰é¡¯ç¤ºï¼‰
    if st.session_state.current_page_index > 0:
        with col1:
            if st.button("â† ä¸Šä¸€é ", key="prev_page_btn"):
                st.session_state.current_page_index -= 1
                st.rerun()

    # ä¸‹ä¸€é ï¼ˆåªæœ‰ç•¶ä¸æ˜¯æœ€å¾Œä¸€é æ™‚æ‰é¡¯ç¤ºï¼‰
    if st.session_state.current_page_index < len(pages) - 1:
        with col4:
            if st.button("ä¸‹ä¸€é  â†’", key="next_page_btn"):
                st.session_state.current_page_index += 1
                st.rerun()


# =========================
# é é¢ 1: ä¸Šå‚³èˆ‡ç¯©é¸
# =========================
if page == "1. ä¸Šå‚³æª”æ¡ˆèˆ‡æ™‚é–“ç¯©é¸":
    st.markdown("### æ­¥é©Ÿ 1: ä¸Šå‚³æª”æ¡ˆèˆ‡æ™‚é–“ç¯©é¸")

    uploaded_file = st.file_uploader("ä¸Šå‚³ç”¨æˆ¶è¡Œç‚ºæ­·ç¨‹è³‡æ–™ (CSV)", type=["csv"])

    if uploaded_file is not None:
        try:
            user_df = pd.read_csv(uploaded_file)
            st.session_state.raw_uploaded_data = user_df
            st.success(f"ä¸Šå‚³æˆåŠŸï¼Œå…± {len(user_df)} ç­†è³‡æ–™")

            required_cols = [
                "user_pseudo_id", "event_time", "action_group", "source",
                "medium", "platform", "staytime", "has_shared", "revisit_count"
            ]
            missing_cols = [col for col in required_cols if col not in user_df.columns]
            if missing_cols:
                st.error(f"ç¼ºå°‘æ¬„ä½ï¼š{', '.join(missing_cols)}")
                st.stop()

            with st.expander("é è¦½è³‡æ–™"):
                st.dataframe(user_df.head(), use_container_width=True)

            user_df['event_time'] = pd.to_datetime(user_df['event_time'])
            min_date = user_df['event_time'].min().date()
            max_date = user_df['event_time'].max().date()

            col1, col2 = st.columns(2)
            with col1:
                start_date = st.date_input("èµ·å§‹æ—¥æœŸ", value=min_date, min_value=min_date, max_value=max_date)
            with col2:
                end_date = st.date_input("æˆªæ­¢æ—¥æœŸ", value=max_date, min_value=min_date, max_value=max_date)

            if start_date > end_date:
                st.error("èµ·å§‹æ—¥æœŸä¸èƒ½å¤§æ–¼æˆªæ­¢æ—¥æœŸ")
                st.session_state.filtered_input_data = None
            else:
                filtered_df = user_df[(user_df['event_time'].dt.date >= start_date) & (user_df['event_time'].dt.date <= end_date)]
                st.session_state.filtered_input_data = filtered_df
                st.info(f"é¸å®šæœŸé–“å…§è³‡æ–™: {len(filtered_df)} ç­† ({start_date} ~ {end_date})")

        except Exception as e:
            st.error(f"ä¸Šå‚³éŒ¯èª¤ï¼š{e}")
            st.session_state.raw_uploaded_data = None

    else:
        st.info("è«‹å…ˆä¸Šå‚³æ•¸æ“šæ–‡ä»¶")
        col1, col2 = st.columns(2)
        with col1:
            st.date_input("èµ·å§‹æ—¥æœŸ", disabled=True)
        with col2:
            st.date_input("æˆªæ­¢æ—¥æœŸ", disabled=True)

    render_next_page_button()


elif page == "2. é æ¸¬èˆ‡çµæœ":
    st.markdown("### æ­¥é©Ÿ 2: åŸ·è¡Œé æ¸¬")

    prediction_ready = (
        st.session_state.get("raw_uploaded_data") is not None and
        st.session_state.get("filtered_input_data") is not None
    )

    if prediction_ready:
        if st.session_state.get("prediction_data") is not None:
            st.success("å·²æœ‰é æ¸¬çµæœ")
            with st.expander("æŸ¥çœ‹é æ¸¬çµæœ", expanded=False):
                st.dataframe(st.session_state.prediction_data.head(), use_container_width=True)
        else:
            if st.button("é–‹å§‹é æ¸¬", use_container_width=True):
                with st.spinner("æ­£åœ¨é€²è¡Œæ¨¡å‹é æ¸¬ï¼Œè«‹ç¨å€™..."):
                    df_result = predict_from_uploaded_csv(st.session_state.filtered_input_data)

                if not df_result.empty:
                    df_result["Marketing_Strategy"] = df_result["Marketing_Strategy"].fillna("æš«ç„¡å»ºè­°ï¼ŒæŒçºŒè§€å¯Ÿ")
                    st.session_state.prediction_data = df_result
                    st.session_state.all_columns = df_result.columns.tolist()
                    st.success("é æ¸¬å®Œæˆ")
                    with st.expander("æŸ¥çœ‹é æ¸¬çµæœ", expanded=False):
                        st.dataframe(df_result.head(), use_container_width=True)
                else:
                    st.error("é æ¸¬çµæœç‚ºç©ºï¼Œè«‹æª¢æŸ¥è³‡æ–™æ ¼å¼")
    else:
        st.button("é–‹å§‹é æ¸¬", disabled=True, help="è«‹å…ˆå®Œæˆè³‡æ–™ä¸Šå‚³èˆ‡ç¯©é¸")
        st.info("è«‹å…ˆå®Œæˆè³‡æ–™ä¸Šå‚³èˆ‡æ™‚é–“ç¯©é¸å¾Œå†é€²è¡Œé æ¸¬")
        
    render_next_page_button()


# =========================
# é é¢ 3: ç¯©é¸èˆ‡ä¸‹è¼‰æª”æ¡ˆ
# =========================

elif page == "3. ç¯©é¸èˆ‡ä¸‹è¼‰æª”æ¡ˆ":
    # ==== æ­¥é©Ÿ 4: é æ¸¬çµæœç¸½è¦½ ====
    st.markdown("### æ­¥é©Ÿ 3: é æ¸¬çµæœç¸½è¦½")

    if st.session_state.get("prediction_data") is not None:
        df = st.session_state.prediction_data
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ç¸½ç”¨æˆ¶æ•¸", len(df))
        with col2:
            st.metric("å¹³å‡ Top1 ä¿¡å¿ƒ", f"{df['Top1_confidence'].mean():.3f}")
        with col3:
            rate_online = (df['Online_conversion_prob'] >= 0.3).mean() * 100
            st.metric("ç¶²æŠ•æ©Ÿç‡ â‰¥0.3 çš„ç”¨æˆ¶", f"{(rate_online/100)*len(df):.0f} ({rate_online:.1f}%)")
        with col4:
            rate_o2o = (df['O2O_reservation_prob'] >= 0.3).mean() * 100
            st.metric("O2O æ©Ÿç‡ â‰¥0.3 çš„ç”¨æˆ¶", f"{(rate_o2o/100)*len(df):.0f} ({rate_o2o:.1f}%)")

        with st.expander("æŸ¥çœ‹å®Œæ•´é æ¸¬çµæœ", expanded=False):
            st.dataframe(df, use_container_width=True)
    else:
        st.info("å®Œæˆé æ¸¬å¾Œå°‡åœ¨æ­¤é¡¯ç¤ºçµæœç¸½è¦½")

    # ==== æ­¥é©Ÿ 5: ç¯©é¸ä¸‹è¼‰æ¢ä»¶ ====
    st.markdown("### æ­¥é©Ÿ 4: ç¯©é¸é æ¸¬çµæœ")

    if st.session_state.get("prediction_data") is not None:
        df = st.session_state.prediction_data.copy()
        df["Marketing_Strategy"].fillna("æš«ç„¡å»ºè­°ï¼ŒæŒçºŒè§€å¯Ÿ", inplace=True)

        # æ­·å²è¡Œç‚ºç¯©é¸
        history_steps = st.selectbox("éå»å¹¾æ­¥å…§", list(range(1,11)), index=5)
        hist_actions = set()
        for i in range(1, history_steps+1):
            col = "last_action_group" if i==1 else f"-{i}_action_group"
            if col in df:
                hist_actions |= set(df[col].dropna())
        selected_hist = st.multiselect("æ­·å²è¡Œç‚ºç¯©é¸", sorted(hist_actions))
        if selected_hist:
            mask = pd.Series(False, index=df.index)
            for i in range(1, history_steps+1):
                col = "last_action_group" if i==1 else f"-{i}_action_group"
                if col in df:
                    mask |= df[col].isin(selected_hist)
            df = df[mask]

        # é æ¸¬è¡Œç‚ºç¯©é¸
        top_n = st.selectbox("TopN ç¯©é¸", [1,2,3,4,5], index=2)
        pred_actions = set()
        for i in range(1, top_n+1):
            col = f"Top{i}_next_action_group"
            if col in df:
                pred_actions |= set(df[col].dropna())
        selected_pred = st.multiselect("é æ¸¬è¡Œç‚ºç¯©é¸", sorted(pred_actions))
        if selected_pred:
            mask = pd.Series(False, index=df.index)
            for i in range(1, top_n+1):
                col = f"Top{i}_next_action_group"
                if col in df:
                    mask |= df[col].isin(selected_pred)
            df = df[mask]

        # ä¿¡å¿ƒé–€æª»
        opt = st.radio("ä¿¡å¿ƒé–€æª»ç­–ç•¥", ["è‡ªå®šç¾©","ä¿å®ˆ(0.4)","å¹³è¡¡(0.3)","ç©æ¥µ(0.2)"], index=2)
        if opt=="ä¿å®ˆ(0.4)":
            min_conf=0.4
        elif opt=="å¹³è¡¡(0.3)":
            min_conf=0.3
        elif opt=="ç©æ¥µ(0.2)":
            min_conf=0.2
        else:
            min_conf = st.number_input("è‡ªå®šç¾©ä¿¡å¿ƒé–€æª»",0.0,1.0,0.3)
        df = df[df["Top1_confidence"]>=min_conf]

        # è½‰æ›æ©Ÿç‡
        if st.checkbox("å•Ÿç”¨è½‰æ›æ©Ÿç‡ç¯©é¸"):
            min_online = st.slider("ç¶²æŠ•æ©Ÿç‡æœ€ä½å€¼",0.0,1.0,0.5)
            min_o2o = st.slider("O2O æ©Ÿç‡æœ€ä½å€¼",0.0,1.0,0.5)
            df = df[(df["Online_conversion_prob"]>=min_online)|(df["O2O_reservation_prob"]>=min_o2o)]

        # è¡ŒéŠ·ç­–ç•¥
        sel_strat = st.multiselect("è¡ŒéŠ·ç­–ç•¥ç¯©é¸", sorted(df["Marketing_Strategy"].unique()))
        if sel_strat:
            df = df[df["Marketing_Strategy"].isin(sel_strat)]

        st.markdown(f"ç¬¦åˆæ¢ä»¶ç­†æ•¸ï¼š{len(df)}")

        # ğŸ”½ æ¬„ä½é¸æ“‡
        st.markdown("**é¸æ“‡è¼¸å‡ºæ¬„ä½**")
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("å…¨é¸", key="select_all"):
                st.session_state.selected_columns = st.session_state.all_columns
        with col2:
            if st.button("æ ¸å¿ƒæ¬„ä½", key="select_core"):
                core_columns = [
                    'user_pseudo_id', 'Top1_next_action_group', 'Top1_confidence',
                    'Top2_next_action_group', 'Top2_confidence',
                    'Top3_next_action_group', 'Top3_confidence',
                    'Online_conversion_prob', 'O2O_reservation_prob', 'Marketing_Strategy'
                ]
                st.session_state.selected_columns = [col for col in core_columns if col in st.session_state.all_columns]
        with col3:
            if st.button("é æ¸¬æ¬„ä½", key="select_prediction"):
                prediction_cols = [
                    'user_pseudo_id', 'Top1_next_action_group', 'Top1_confidence',
                    'Top2_next_action_group', 'Top2_confidence',
                    'Top3_next_action_group', 'Top3_confidence',
                    'Top4_next_action_group', 'Top4_confidence',
                    'Top5_next_action_group', 'Top5_confidence',
                    'Online_conversion_prob', 'O2O_reservation_prob'
                ]
                st.session_state.selected_columns = [col for col in prediction_cols if col in st.session_state.all_columns]

        # æ¬„ä½ä¸‹æ‹‰
        if 'selected_columns' not in st.session_state:
            st.session_state.selected_columns = st.session_state.all_columns

        selected_columns = st.multiselect(
            "é¸æ“‡è¦è¼¸å‡ºçš„æ¬„ä½",
            options=st.session_state.all_columns,
            default=st.session_state.selected_columns,
            key="column_selector"
        )

        if selected_columns != st.session_state.selected_columns:
            st.session_state.selected_columns = selected_columns
            st.rerun()

        # æª”æ¡ˆä¸‹è¼‰
        fname = st.text_input("è¼¸å‡ºæª”å", "result")
        if not df.empty and selected_columns and fname.strip():
            csv = df[selected_columns].to_csv(index=False).encode("utf-8-sig")
            st.download_button("ä¸‹è¼‰çµæœ CSV", data=csv, file_name=f"{fname}.csv", mime="text/csv", use_container_width=True)
        elif not selected_columns:
            st.info("è«‹å…ˆé¸æ“‡è¼¸å‡ºæ¬„ä½")
        elif not fname.strip():
            st.info("è«‹è¼¸å…¥æª”å")
        else:
            st.warning("ç›®å‰æ²’æœ‰è³‡æ–™ç¬¦åˆæ¢ä»¶å¯ä¾›ä¸‹è¼‰")

    else:
        st.info("å®Œæˆé æ¸¬å¾Œå³å¯ç¯©é¸çµæœ")
        
    st.session_state["filtered_prediction_data"] = df
    render_next_page_button()

# =========================
# é é¢ 4: çµ±è¨ˆåœ–è¡¨åˆ†æ
# =========================

elif page == "4. çµ±è¨ˆåœ–è¡¨åˆ†æ":
    st.markdown("### çµ±è¨ˆåœ–è¡¨åˆ†æ")

    # å–å¾—åŸå§‹èˆ‡ç¯©é¸å¾Œè³‡æ–™
    original_df = st.session_state.get("prediction_data")
    filtered_df = st.session_state.get("filtered_prediction_data")

    # åŠ å…¥è³‡æ–™ä¾†æºåˆ‡æ›æŒ‰éˆ•
    data_source = st.radio(
        "è³‡æ–™ä¾†æºé¸æ“‡",
        ["å…¨éƒ¨é æ¸¬çµæœ", "é é¢ä¸‰ç¯©é¸çµæœ"],
        index=1 if filtered_df is not None else 0,
        horizontal=True
    )

    # æ ¹æ“šé¸æ“‡æ±ºå®šè¦ç”¨å“ªä»½è³‡æ–™
    df = filtered_df if data_source == "é é¢ä¸‰ç¯©é¸çµæœ" and filtered_df is not None else original_df

    if df is not None and not df.empty:
        tab1, tab2, tab3, tab4 = st.tabs(["è¡Œç‚ºåˆ†ä½ˆ", "ä¿¡å¿ƒåˆ†æ•¸", "è½‰æ›åˆ†æ", "ç­–ç•¥åˆ†ä½ˆ"])

        with tab1:
            chart_df = df["Top1_next_action_group"].value_counts().reset_index()
            chart_df.columns = ["action_group", "count"]
            fig1 = px.bar(chart_df, x="action_group", y="count", title="Top1 é æ¸¬è¡Œç‚ºåˆ†ä½ˆ")
            fig1.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig1, use_container_width=True)

        with tab2:
            fig2 = px.histogram(
                df,
                x="Top1_confidence",
                nbins=20,
                title="Top1 é æ¸¬ä¿¡å¿ƒåˆ†æ•¸åˆ†ä½ˆï¼ˆäººæ•¸ï¼‰",
                labels={"Top1_confidence": "Top1 ä¿¡å¿ƒåˆ†æ•¸", "count": "äººæ•¸"}
            )
            fig2.update_layout(bargap=0)
            st.plotly_chart(fig2, use_container_width=True)

        with tab3:
            st.markdown("#### ç¶²è·¯æŠ•ä¿è½‰æ›æ©Ÿç‡åˆ†ä½ˆ")
            fig3_online = px.histogram(
                df,
                x="Online_conversion_prob",
                nbins=20,
                title="ç¶²è·¯æŠ•ä¿è½‰æ›æ©Ÿç‡åˆ†ä½ˆï¼ˆäººæ•¸ï¼‰",
                labels={"Online_conversion_prob": "ç¶²è·¯æŠ•ä¿è½‰æ›æ©Ÿç‡", "count": "äººæ•¸"}
            )
            fig3_online.update_layout(bargap=0)
            st.plotly_chart(fig3_online, use_container_width=True)

            st.markdown("#### O2O é ç´„è½‰æ›æ©Ÿç‡åˆ†ä½ˆ")
            fig3_o2o = px.histogram(
                df,
                x="O2O_reservation_prob",
                nbins=20,
                title="O2O é ç´„è½‰æ›æ©Ÿç‡åˆ†ä½ˆï¼ˆäººæ•¸ï¼‰",
                labels={"O2O_reservation_prob": "O2O é ç´„æ©Ÿç‡", "count": "äººæ•¸"}
            )
            fig3_o2o.update_layout(bargap=0)
            st.plotly_chart(fig3_o2o, use_container_width=True)

        with tab4:
            strategy_df = df["Marketing_Strategy"].fillna("æš«ç„¡å»ºè­°ï¼ŒæŒçºŒè§€å¯Ÿ").value_counts().reset_index()
            strategy_df.columns = ["strategy", "count"]
            fig4 = px.pie(
                strategy_df,
                names="strategy",
                values="count",
                title="å»ºè­°è¡ŒéŠ·ç­–ç•¥åˆ†ä½ˆï¼ˆå«æŒçºŒè§€å¯Ÿï¼‰"
            )
            st.plotly_chart(fig4, use_container_width=True)

    else:
        st.info("å®Œæˆé æ¸¬å¾Œï¼Œé€™è£¡å°‡é¡¯ç¤ºè©³ç´°çš„æ•¸æ“šåˆ†æåœ–è¡¨")
        tab1, tab2, tab3, tab4 = st.tabs(["è¡Œç‚ºåˆ†ä½ˆ", "ä¿¡å¿ƒåˆ†æ•¸", "è½‰æ›åˆ†æ", "ç­–ç•¥åˆ†ä½ˆ"])

        with tab1:
            st.markdown("**Top1 é æ¸¬è¡Œç‚ºåˆ†ä½ˆåœ–**")
            st.info("å°‡é¡¯ç¤ºå„ç¨®é æ¸¬è¡Œç‚ºçš„ç”¨æˆ¶æ•¸é‡åˆ†ä½ˆ")

        with tab2:
            st.markdown("**Top1 é æ¸¬ä¿¡å¿ƒåˆ†æ•¸åˆ†ä½ˆï¼ˆäººæ•¸ï¼‰**")
            st.info("å°‡é¡¯ç¤ºæ¨¡å‹ä¿¡å¿ƒåˆ†æ•¸åœ¨å„å€é–“çš„äººæ•¸åˆ†ä½ˆ")

        with tab3:
            st.markdown("**è½‰æ›æ©Ÿç‡åˆ†ä½ˆåœ–ï¼ˆäººæ•¸ï¼‰**")
            st.info("å°‡é¡¯ç¤ºç¶²è·¯æŠ•ä¿ èˆ‡ é ç´„ O2O çš„è½‰æ›æ©Ÿç‡èˆ‡äººæ•¸åˆ†ä½ˆæƒ…æ³")

        with tab4:
            st.markdown("**å»ºè­°è¡ŒéŠ·ç­–ç•¥åˆ†ä½ˆ**")
            st.info("å°‡é¡¯ç¤ºç³»çµ±å»ºè­°çš„è¡ŒéŠ·ç­–ç•¥é¡å‹æ¯”ä¾‹")

    render_next_page_button()

# cd CathayLifeProject
# .venv\Scripts\Activate
# streamlit run app.py